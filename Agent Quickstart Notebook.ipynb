{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d74b7227-593d-4df0-b33b-cac3720f03e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# クイックスタート: Mosaic AI Agent Frameworkを使用してエージェントを構築、テスト、デプロイする\n",
    "このクイックスタートノートブックでは、Mosaic AI Agent Framework ([AWS](https://docs.databricks.com/aws/ja/generative-ai/guide/introduction-generative-ai-apps#what-are-gen-ai-apps) | [Azure](https://learn.microsoft.com/ja-jp/azure/databricks/generative-ai/guide/introduction-generative-ai-apps#what-are-gen-ai-apps) | [GCP](https://docs.databricks.com/gcp/ja/generative-ai/guide/introduction-generative-ai-apps)) を使用して、Databricks上で生成AIエージェントを構築、テスト、デプロイする方法を示します。([AWS](https://docs.databricks.com/aws/ja/generative-ai/agent-framework/build-genai-apps#-mosaic-ai-agent-framework) | [Azure](https://learn.microsoft.com/ja-jp/azure/databricks/generative-ai/agent-framework/build-genai-apps#-mosaic-ai-agent-framework) | [GCP](https://docs.databricks.com/gcp/ja/generative-ai/agent-framework/build-genai-apps#-mosaic-ai-agent-framework))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ccb46b22-8e01-4380-a8aa-a5c4573ed7e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## エージェントの定義とテスト\n",
    "このセクションでは、以下の属性を持つシンプルなエージェントを定義し、テストします。\n",
    "\n",
    "- エージェントは、Databricks Foundation Model APIで提供されるLLMを使用します。([AWS](https://docs.databricks.com/aws/ja/machine-learning/foundation-model-apis) | [Azure](https://learn.microsoft.com/ja-jp/azure/databricks/machine-learning/foundation-model-apis/) | [GCP](https://docs.databricks.com/gcp/ja/machine-learning/foundation-model-apis))\n",
    "- エージェントは、Databricks Unity Catalog上の組み込みPythonコードインタープリターツールにアクセスできます。このツールを使用して、ユーザーの質問に応答するためにLLM生成コードを実行できます。([AWS](https://docs.databricks.com/aws/ja/generative-ai/agent-framework/code-interpreter-tools#built-in-python-executor-tool) | [Azure](https://learn.microsoft.com/ja-jp/azure/databricks/generative-ai/agent-framework/code-interpreter-tools) | [GCP](https://docs.databricks.com/gcp/ja/generative-ai/agent-framework/code-interpreter-tools))\n",
    "\n",
    "LLMエンドポイントをクエリするために`databricks_openai` SDKを使用します。([AWS](https://docs.databricks.com/aws/ja/generative-ai/agent-framework/author-agent#requirements) | [Azure](https://learn.microsoft.com/ja-jp/azure/databricks/generative-ai/agent-framework/author-agent#requirements) | [GCP](https://docs.databricks.com/gcp/ja/generative-ai/agent-framework/author-agent#requirements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00b7d312-e9f6-4daa-8f1d-bca73b7238d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq mlflow databricks-openai databricks-agents\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2500c116-f700-42c8-857d-046df6897aa0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 以下のスニペットは、候補の中からDatabricksワークスペースで利用可能な最初のLLM APIを選択しようとします。\n",
    "# LLM_ENDPOINT_NAMEを指定するだけにオーバーライドして簡略化できます。\n",
    "LLM_ENDPOINT_NAME = None\n",
    "\n",
    "from databricks.sdk import WorkspaceClient\n",
    "def is_endpoint_available(endpoint_name):\n",
    "  try:\n",
    "    client = WorkspaceClient().serving_endpoints.get_open_ai_client()\n",
    "    client.chat.completions.create(model=endpoint_name, messages=[{\"role\": \"user\", \"content\": \"AIとは何ですか？\"}])\n",
    "    return True\n",
    "  except Exception:\n",
    "    return False\n",
    "  \n",
    "client = WorkspaceClient()\n",
    "for candidate_endpoint_name in [\"databricks-claude-3-7-sonnet\", \"databricks-meta-llama-3-3-70b-instruct\"]:\n",
    "    if is_endpoint_available(candidate_endpoint_name):\n",
    "      LLM_ENDPOINT_NAME = candidate_endpoint_name\n",
    "assert LLM_ENDPOINT_NAME is not None, \"LLM_ENDPOINT_NAMEを指定してください\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ad85702-3943-42b0-a665-6a636ed69a51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import mlflow\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks_openai import UCFunctionToolkit, DatabricksFunctionClient\n",
    "\n",
    "# LLM呼び出しからのトレースを自動的にログに記録してデバッグを容易にする\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "# Databricksモデルサービングエンドポイントと通信するように構成されたOpenAIクライアントを取得\n",
    "# これを使用してエージェント内のLLMにクエリを送信する\n",
    "openai_client = WorkspaceClient().serving_endpoints.get_open_ai_client()\n",
    "\n",
    "# Databricks組み込みツールをロード（ステートレスなPythonコードインタープリターツール）\n",
    "client = DatabricksFunctionClient()\n",
    "builtin_tools = UCFunctionToolkit(\n",
    "    function_names=[\"system.ai.python_exec\"], client=client\n",
    ").tools\n",
    "for tool in builtin_tools:\n",
    "    del tool[\"function\"][\"strict\"]\n",
    "\n",
    "\n",
    "def call_tool(tool_name, parameters):\n",
    "    if tool_name == \"system__ai__python_exec\":\n",
    "        return DatabricksFunctionClient().execute_function(\n",
    "            \"system.ai.python_exec\", parameters=parameters\n",
    "        )\n",
    "    raise ValueError(f\"未知のツール: {tool_name}\")\n",
    "\n",
    "\n",
    "def run_agent(prompt):\n",
    "    \"\"\"\n",
    "    ユーザープロンプトをLLMに送信し、LLMの応答メッセージのリストを返す\n",
    "    LLMは必要に応じてコードインタープリターツールを呼び出してユーザーに応答することができる\n",
    "    \"\"\"\n",
    "    result_msgs = []\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=LLM_ENDPOINT_NAME,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        tools=builtin_tools,\n",
    "    )\n",
    "    msg = response.choices[0].message\n",
    "    result_msgs.append(msg.to_dict())\n",
    "\n",
    "    # モデルがツールを実行した場合、それを呼び出す\n",
    "    if msg.tool_calls:\n",
    "        call = msg.tool_calls[0]\n",
    "        tool_result = call_tool(call.function.name, json.loads(call.function.arguments))\n",
    "        result_msgs.append(\n",
    "            {\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": tool_result.value,\n",
    "                \"name\": call.function.name,\n",
    "                \"tool_call_id\": call.id,\n",
    "            }\n",
    "        )\n",
    "    return result_msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f402ded-a2b2-42e3-87b7-b21c671331b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "answer = run_agent(\"429の平方根は何ですか？\")\n",
    "for message in answer:\n",
    "    print(f'{message[\"role\"]}: {message[\"content\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c94061c2-f519-4213-8e4a-4321d72a3fad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## エージェントコードの準備\n",
    "\n",
    "エージェントの定義をMLflowの[ChatAgentインターフェース](https://mlflow.org/docs/latest/api_reference/python_api/mlflow.pyfunc.html#mlflow.pyfunc.ChatAgent)でラップして、コードをログに記録する準備をします。\n",
    "\n",
    "MLflowの標準エージェント作成インターフェースを使用することで、エージェントとチャットしたり、デプロイ後に他の人と共有したりするための組み込みUIを利用できます。([AWS](https://docs.databricks.com/aws/ja/generative-ai/agent-framework/author-agent#-use-chatagent-to-author-agents) | [Azure](https://learn.microsoft.com/ja-jp/azure/databricks/generative-ai/agent-framework/author-agent) | [GCP](https://docs.databricks.com/gcp/ja/generative-ai/agent-framework/author-agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaaeee19-bb4c-4c0e-bf1a-8ef84432625f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "import mlflow\n",
    "from typing import Any, Optional\n",
    "\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import ChatAgentMessage, ChatAgentResponse, ChatContext\n",
    "\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "class QuickstartAgent(ChatAgent):\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        # 1. 入力メッセージから最後のユーザープロンプトを抽出\n",
    "        prompt = messages[-1].content\n",
    "\n",
    "        # 2. run_agentを呼び出して、応答メッセージのリストを取得\n",
    "        raw_msgs = run_agent(prompt)\n",
    "\n",
    "        # 3. 各応答メッセージをChatAgentMessageにマップし、応答を返す\n",
    "        out = []\n",
    "        for m in raw_msgs:\n",
    "            out.append(ChatAgentMessage(id=uuid.uuid4().hex, **m))\n",
    "\n",
    "        return ChatAgentResponse(messages=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1ee1e3e-3590-4c15-b684-971037014cd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "AGENT = QuickstartAgent()\n",
    "for response_message in AGENT.predict(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"429の平方根は何ですか？\"}]}\n",
    ").messages:\n",
    "    print(f\"role: {response_message.role}, content: {response_message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94ae452f-37f1-4983-9b70-caa5185616a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## エージェントの記録\n",
    "\n",
    "エージェントをログに記録し、Unity Catalogにモデルとして登録します ([AWS](https://docs.databricks.com/aws/ja/machine-learning/manage-model-lifecycle/) | [Azure](https://learn.microsoft.com/ja-jp/azure/databricks/machine-learning/manage-model-lifecycle/) | [GCP](https://docs.databricks.com/gcp/ja/machine-learning/manage-model-lifecycle/))。このステップでは、エージェントコードとその依存関係を単一のアーティファクトにパッケージ化し、サービングエンドポイントにデプロイします。\n",
    "\n",
    "以下のコードセルは次のことを行います：\n",
    "\n",
    "1. 上記のエージェントコードをコピーして、単一のセルに結合します。\n",
    "1. セルの先頭に `%%writefile` セルマジックコマンドを追加して、エージェントコードを `quickstart_agent.py` というファイルに保存します。\n",
    "1. セルの下部に [mlflow.models.set_model()](https://mlflow.org/docs/latest/model#models-from-code) 呼び出しを追加します。これにより、エージェントがデプロイされたときに予測を行うために使用するPythonエージェントオブジェクトをMLflowに伝えます。\n",
    "1. MLflow APIを使用して `quickstart_agent.py` ファイル内のエージェントコードをログに記録します ([AWS](https://docs.databricks.com/aws/ja/generative-ai/agent-framework/log-agent) | [Azure](https://learn.microsoft.com/ja-jp/azure/databricks/generative-ai/agent-framework/log-agent) | [GCP](https://docs.databricks.com/gcp/ja/generative-ai/agent-framework/log-agent))。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbdca20f-fa2f-4626-9d79-7264a0212cf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile quickstart_agent.py\n",
    "\n",
    "import json\n",
    "import uuid\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks_openai import UCFunctionToolkit, DatabricksFunctionClient\n",
    "from typing import Any, Optional\n",
    "\n",
    "import mlflow\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import ChatAgentMessage, ChatAgentResponse, ChatContext\n",
    "\n",
    "# Databricksのモデルサービングエンドポイントと通信するために設定されたOpenAIクライアントを取得\n",
    "# これを使ってエージェント内でLLMに問い合わせる\n",
    "openai_client = WorkspaceClient().serving_endpoints.get_open_ai_client()\n",
    "\n",
    "# 以下のスニペットは、Databricksワークスペース内で利用可能な最初のLLM APIを\n",
    "# 複数の候補から選択しようとします。必要に応じてLLM_ENDPOINT_NAMEを直接指定して簡略化可能です。\n",
    "LLM_ENDPOINT_NAME = None\n",
    "\n",
    "def is_endpoint_available(endpoint_name):\n",
    "  try:\n",
    "    client = WorkspaceClient().serving_endpoints.get_open_ai_client()\n",
    "    client.chat.completions.create(model=endpoint_name, messages=[{\"role\": \"user\", \"content\": \"AIとは何ですか？\"}])\n",
    "    return True\n",
    "  except Exception:\n",
    "    return False\n",
    "  \n",
    "for candidate_endpoint_name in [\"databricks-claude-3-7-sonnet\", \"databricks-meta-llama-3-3-70b-instruct\"]:\n",
    "    if is_endpoint_available(candidate_endpoint_name):\n",
    "      LLM_ENDPOINT_NAME = candidate_endpoint_name\n",
    "assert LLM_ENDPOINT_NAME is not None, \"LLM_ENDPOINT_NAMEを指定してください\"\n",
    "\n",
    "# LLM呼び出しの自動トレースを有効化\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "# Databricks組み込みツール（ステートレスなPythonコードインタプリターツール）をロード\n",
    "client = DatabricksFunctionClient()\n",
    "builtin_tools = UCFunctionToolkit(function_names=[\"system.ai.python_exec\"], client=client).tools\n",
    "for tool in builtin_tools:\n",
    "    del tool[\"function\"][\"strict\"]\n",
    "\n",
    "def call_tool(tool_name, parameters):\n",
    "    if tool_name == \"system__ai__python_exec\":\n",
    "        return DatabricksFunctionClient().execute_function(\"system.ai.python_exec\", parameters=parameters)\n",
    "    raise ValueError(f\"不明なツールです: {tool_name}\")\n",
    "\n",
    "def run_agent(prompt):\n",
    "    \"\"\"\n",
    "    ユーザープロンプトをLLMに送信し、LLMの応答メッセージのリストを返す\n",
    "    必要に応じて、LLMはコードインタプリターツールを呼び出してユーザーに応答可能\n",
    "    \"\"\"\n",
    "    result_msgs = []\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=LLM_ENDPOINT_NAME,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        tools=builtin_tools,\n",
    "    )\n",
    "    msg = response.choices[0].message\n",
    "    result_msgs.append(msg.to_dict())\n",
    "\n",
    "    # モデルがツールを実行した場合は呼び出す\n",
    "    if msg.tool_calls:\n",
    "        call = msg.tool_calls[0]\n",
    "        tool_result = call_tool(call.function.name, json.loads(call.function.arguments))\n",
    "        result_msgs.append({\"role\": \"tool\", \"content\": tool_result.value, \"name\": call.function.name, \"tool_call_id\": call.id})\n",
    "    return result_msgs\n",
    "\n",
    "class QuickstartAgent(ChatAgent):\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        prompt = messages[-1].content\n",
    "        raw_msgs = run_agent(prompt)\n",
    "        out = []\n",
    "        for m in raw_msgs:\n",
    "            out.append(ChatAgentMessage(\n",
    "                id=uuid.uuid4().hex,\n",
    "                **m\n",
    "            ))\n",
    "\n",
    "        return ChatAgentResponse(messages=out)\n",
    "\n",
    "AGENT = QuickstartAgent()\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0decec2c-13f8-4bf1-85e0-f8b33eac9753",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5185465-6345-46fe-b49d-da4e643cecd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint\n",
    "from pkg_resources import get_distribution\n",
    "from quickstart_agent import LLM_ENDPOINT_NAME\n",
    "\n",
    "# モデルをワークスペースのデフォルトカタログに登録\n",
    "# 必要に応じてカタログ（例: \"main\"）およびスキーマ名（例: \"custom_schema\"）を指定し、\n",
    "# エージェントを別の場所に登録する\n",
    "catalog_name = \"takaakiyayoi_catalog\"\n",
    "schema_name = \"databricks_101\"\n",
    "registered_model_name = f\"{catalog_name}.{schema_name}.quickstart_agent\"\n",
    "\n",
    "# Databricks製品リソースを指定し、エージェントがこれらのリソースにアクセスできるようにする\n",
    "# （組み込みのPythonコードインタプリターツールとLLMサービングエンドポイント）\n",
    "# これにより、エージェントがデプロイされる際にDatabricksが自動的に認証を構成できるようにする\n",
    "resources = [\n",
    "    DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME),\n",
    "    DatabricksFunction(function_name=\"system.ai.python_exec\"),\n",
    "]\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"agent\",\n",
    "        python_model=\"quickstart_agent.py\",\n",
    "        extra_pip_requirements=[\n",
    "            f\"databricks-connect=={get_distribution('databricks-connect').version}\"\n",
    "        ],\n",
    "        resources=resources,\n",
    "        registered_model_name=registered_model_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d60087e6-077f-484c-9e14-f699ddafa5eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## エージェントのデプロイ\n",
    "\n",
    "以下のセルを実行してエージェントをデプロイします ([AWS](https://docs.databricks.com/aws/ja/generative-ai/agent-framework/deploy-agent) | [Azure](https://learn.microsoft.com/ja-jp/azure/databricks/generative-ai/agent-framework/deploy-agent) | [GCP](https://docs.databricks.com/gcp/ja/generative-ai/agent-framework/deploy-agent))。エージェントエンドポイントが起動すると、AI Playground ([AWS](https://docs.databricks.com/aws/ja/large-language-models/ai-playground) | [Azure](https://learn.microsoft.com/ja-jp/azure/databricks/large-language-models/ai-playground) | [GCP](https://docs.databricks.com/gcp/ja/large-language-models/ai-playground)) を介してエージェントとチャットしたり、ステークホルダーと共有して初期フィードバックを得たり ([AWS](https://docs.databricks.com/aws/ja/generative-ai/agent-evaluation/review-app) | [Azure](https://learn.microsoft.com/ja-jp/azure/databricks/generative-ai/agent-evaluation/review-app) | [GCP](https://docs.databricks.com/gcp/ja/generative-ai/agent-evaluation/review-app)) することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e52e933-400c-4ce0-8ddd-bd6f1e1a3925",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "deployment_info = agents.deploy(\n",
    "    model_name=registered_model_name,\n",
    "    model_version=logged_agent_info.registered_model_version,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Agent Quickstart Notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
